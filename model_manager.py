"""
æ¨¡å‹ç®¡ç†å™¨ - åŠ è½½å’Œç®¡ç†æœ¬åœ°LLMæ¨¡å‹ï¼ˆMLX ç‰ˆæœ¬ï¼‰
æ”¯æŒ MLX-LM æ ¼å¼çš„æœ¬åœ°æ¨¡å‹å’Œ LoRA é€‚é…å™¨
"""

import os
import json
import logging
from typing import Generator, Optional, Dict, Any
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def resolve_saves_path(saves_dir: str = "mlx/saves/qwen-lora") -> Optional[Path]:
    """
    è§£æé€‚é…å™¨ä¿å­˜ç›®å½•è·¯å¾„
    
    Args:
        saves_dir: ä¿å­˜ç›®å½•è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•æˆ–ç»å¯¹è·¯å¾„ï¼‰
        
    Returns:
        è§£æåçš„è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
    """
    saves_path = Path(saves_dir)
    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•ä»å½“å‰å·¥ä½œç›®å½•å’Œè„šæœ¬ç›®å½•æŸ¥æ‰¾
    if not saves_path.is_absolute():
        # å…ˆå°è¯•å½“å‰å·¥ä½œç›®å½•
        if not saves_path.exists():
            # å°è¯•ä»è„šæœ¬æ‰€åœ¨ç›®å½•ï¼ˆfine-tune ç›®å½•ï¼‰
            script_dir = Path(__file__).parent
            saves_path = script_dir / saves_dir
            if not saves_path.exists():
                # å°è¯•ä»é¡¹ç›®æ ¹ç›®å½•
                project_root = script_dir.parent if script_dir.name == "fine-tune" else script_dir
                saves_path = project_root / saves_dir
    
    if not saves_path.exists():
        logger.warning(f"é€‚é…å™¨ä¿å­˜ç›®å½•ä¸å­˜åœ¨: {saves_path}")
        return None
    
    return saves_path


def find_latest_adapter(saves_dir: str = "mlx/saves/qwen-lora") -> Optional[Path]:
    """
    è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„é€‚é…å™¨
    
    Args:
        saves_dir: ä¿å­˜ç›®å½•è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•æˆ–ç»å¯¹è·¯å¾„ï¼‰
        
    Returns:
        æœ€æ–°çš„é€‚é…å™¨æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
    """
    saves_path = resolve_saves_path(saves_dir)
    if saves_path is None:
        return None
    
    # æŸ¥æ‰¾æ‰€æœ‰ train_* ç›®å½•
    train_dirs = sorted(
        saves_path.glob("train_*"), 
        key=lambda p: p.stat().st_mtime, 
        reverse=True
    )
    
    for train_dir in train_dirs:
        adapter_file = train_dir / "adapters.npz"
        if adapter_file.exists():
            logger.info(f"æ‰¾åˆ°é€‚é…å™¨: {adapter_file}")
            return adapter_file
    
    logger.warning("æœªæ‰¾åˆ°ä»»ä½•é€‚é…å™¨æ–‡ä»¶")
    return None


def load_adapter_config(adapter_path: Path) -> Optional[Dict[str, Any]]:
    """
    åŠ è½½é€‚é…å™¨é…ç½®æ–‡ä»¶
    
    Args:
        adapter_path: é€‚é…å™¨æ–‡ä»¶è·¯å¾„ï¼ˆadapters.npzï¼‰
        
    Returns:
        é…ç½®å­—å…¸ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å› None
    """
    # adapter_config.json åœ¨ adapters.npz çš„åŒä¸€ç›®å½•ä¸‹
    config_file = adapter_path.parent / "adapter_config.json"
    if not config_file.exists():
        return None
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.warning(f"æ— æ³•è¯»å–é€‚é…å™¨é…ç½® {config_file}: {e}")
        return None


def extract_adapter_info(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä»é€‚é…å™¨é…ç½®ä¸­æå–é‡è¦ä¿¡æ¯
    
    Args:
        config: é€‚é…å™¨é…ç½®å­—å…¸
        
    Returns:
        æå–çš„é‡è¦ä¿¡æ¯å­—å…¸
    """
    info = {}
    
    # LoRA å‚æ•°
    if "lora_parameters" in config:
        lora = config["lora_parameters"]
        info["lora_rank"] = lora.get("rank", "N/A")
        info["lora_scale"] = lora.get("scale", "N/A")
        info["lora_dropout"] = lora.get("dropout", "N/A")
    
    # è®­ç»ƒå‚æ•°
    info["learning_rate"] = config.get("learning_rate", "N/A")
    info["batch_size"] = config.get("batch_size", "N/A")
    info["iters"] = config.get("iters", "N/A")
    info["num_layers"] = config.get("num_layers", "N/A")
    info["max_seq_length"] = config.get("max_seq_length", "N/A")
    
    # å…¶ä»–é‡è¦å‚æ•°
    info["grad_checkpoint"] = config.get("grad_checkpoint", False)
    info["optimizer"] = config.get("optimizer", "N/A")
    
    return info


def list_all_adapters(saves_dir: str = "mlx/saves/qwen-lora") -> list:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é€‚é…å™¨ï¼ˆæŒ‰æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
    
    Args:
        saves_dir: ä¿å­˜ç›®å½•è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•æˆ–ç»å¯¹è·¯å¾„ï¼‰
        
    Returns:
        é€‚é…å™¨åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
        - path: é€‚é…å™¨æ–‡ä»¶è·¯å¾„ï¼ˆå­—ç¬¦ä¸²ï¼‰
        - name: é€‚é…å™¨åç§°ï¼ˆtrain_YYYY-MM-DD-HH-MM-SSï¼‰
        - mtime: ä¿®æ”¹æ—¶é—´æˆ³
        - config: é€‚é…å™¨é…ç½®ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    """
    saves_path = resolve_saves_path(saves_dir)
    if saves_path is None:
        return []
    
    adapters = []
    # æŸ¥æ‰¾æ‰€æœ‰ train_* ç›®å½•
    train_dirs = sorted(
        saves_path.glob("train_*"), 
        key=lambda p: p.stat().st_mtime, 
        reverse=True  # æœ€æ–°çš„åœ¨å‰
    )
    
    for train_dir in train_dirs:
        adapter_file = train_dir / "adapters.npz"
        if adapter_file.exists():
            adapter_info = {
                "path": str(adapter_file),
                "name": train_dir.name,
                "mtime": adapter_file.stat().st_mtime
            }
            
            # å°è¯•åŠ è½½é…ç½®ä¿¡æ¯
            config = load_adapter_config(adapter_file)
            if config:
                adapter_info["config"] = extract_adapter_info(config)
            
            adapters.append(adapter_info)
    
    return adapters


def detect_model_name_from_path(model_path: str) -> str:
    """
    ä»æ¨¡å‹è·¯å¾„è‡ªåŠ¨æ£€æµ‹æ¨¡å‹åç§°
    
    ä¼˜å…ˆçº§:
    1. config.json ä¸­çš„ model_name æˆ– _name_or_path
    2. è·¯å¾„ä¸­çš„æœ€åä¸¤çº§ç›®å½• (å¦‚ Qwen/Qwen3-Next-80B-A3B-Instruct)
    3. è·¯å¾„ä¸­çš„æœ€åä¸€çº§ç›®å½•
    
    Args:
        model_path: æ¨¡å‹æœ¬åœ°è·¯å¾„æˆ– HuggingFace æ¨¡å‹ ID
        
    Returns:
        æ£€æµ‹åˆ°çš„æ¨¡å‹åç§°
    """
    try:
        # å¦‚æœæ˜¯ HuggingFace æ¨¡å‹ IDï¼ˆåŒ…å« /ï¼‰ï¼Œç›´æ¥è¿”å›
        if "/" in model_path and not Path(model_path).exists():
            return model_path
        
        # å°è¯•ä» config.json è¯»å–
        config_path = Path(model_path) / "config.json"
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # ä¼˜å…ˆä½¿ç”¨ _name_or_path
                if "_name_or_path" in config and config["_name_or_path"]:
                    name = config["_name_or_path"]
                    # å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼Œæå–æœ€åä¸¤çº§
                    if "/" in name or "\\" in name:
                        parts = Path(name).parts
                        if len(parts) >= 2:
                            return f"{parts[-2]}/{parts[-1]}"
                        return parts[-1]
                    return name
                
                # å°è¯• model_name
                if "model_name" in config and config["model_name"]:
                    return config["model_name"]
        
        # ä»è·¯å¾„æå–æœ€åä¸¤çº§ (å¦‚ Qwen/Qwen3-Next-80B-A3B-Instruct)
        path_obj = Path(model_path)
        parts = path_obj.parts
        
        if len(parts) >= 2:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„æ¨¡å‹ä»“åº“ç»“æ„
            if parts[-2] in ["models", "hub", "model"]:
                # å¦‚æœå€’æ•°ç¬¬äºŒçº§æ˜¯ models/hubï¼Œå†å¾€å‰å–
                if len(parts) >= 3:
                    return f"{parts[-3]}/{parts[-1]}"
            else:
                return f"{parts[-2]}/{parts[-1]}"
        
        # åªè¿”å›æœ€åä¸€çº§
        return parts[-1]
        
    except Exception as e:
        logger.warning(f"Failed to detect model name from config: {e}")
        # å›é€€åˆ°è·¯å¾„æœ€åä¸€çº§æˆ–åŸè·¯å¾„
        return Path(model_path).name if Path(model_path).exists() else model_path


class ModelManager:
    """æœ¬åœ°æ¨¡å‹ç®¡ç†å™¨ï¼ˆMLX ç‰ˆæœ¬ï¼‰"""
    
    def __init__(
        self, 
        model_path: str, 
        model_name: Optional[str] = None,
        adapter_path: Optional[str] = None,
        no_adapter: bool = False,
        saves_dir: str = "mlx/saves/qwen-lora"
    ):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„æˆ– HuggingFace æ¨¡å‹ ID
            model_name: æ¨¡å‹æ˜¾ç¤ºåç§°ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
            adapter_path: é€‚é…å™¨æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ï¼‰
            no_adapter: æ˜¯å¦ä¸ä½¿ç”¨é€‚é…å™¨ï¼ˆä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼‰
            saves_dir: é€‚é…å™¨ä¿å­˜ç›®å½•ï¼ˆç”¨äºè‡ªåŠ¨æŸ¥æ‰¾ï¼‰
        """
        self.model_path = model_path
        # å¦‚æœæœªæä¾›åç§°ï¼Œè‡ªåŠ¨æ£€æµ‹
        if model_name is None or model_name.strip() == "":
            self.model_name = detect_model_name_from_path(model_path)
            logger.info(f"Auto-detected model name: {self.model_name}")
        else:
            self.model_name = model_name
        
        self.model = None
        self.tokenizer = None
        self.generate_fn = None
        
        # é€‚é…å™¨é…ç½®
        self.no_adapter = no_adapter
        self.saves_dir = saves_dir
        
        # ç¡®å®šé€‚é…å™¨è·¯å¾„
        if no_adapter:
            self.adapter_path = None
            logger.info("é…ç½®ä¸ºä¸ä½¿ç”¨é€‚é…å™¨ï¼ˆåŸºç¡€æ¨¡å‹ï¼‰")
        elif adapter_path:
            self.adapter_path = Path(adapter_path)
            logger.info(f"ä½¿ç”¨æŒ‡å®šçš„é€‚é…å™¨: {self.adapter_path}")
        else:
            # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„é€‚é…å™¨
            self.adapter_path = find_latest_adapter(saves_dir)
            if self.adapter_path:
                logger.info(f"è‡ªåŠ¨æ‰¾åˆ°é€‚é…å™¨: {self.adapter_path}")
            else:
                logger.warning("æœªæ‰¾åˆ°é€‚é…å™¨ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨¡å‹")
        
        # æ£€æŸ¥ MLX-LM æ˜¯å¦å¯ç”¨
        try:
            from mlx_lm import load, generate
            self._mlx_available = True
            logger.debug("MLX-LM å¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            self._mlx_available = False
            logger.error(f"MLX-LM å¯¼å…¥å¤±è´¥ (ImportError): {e}")
            logger.error("è¯·è¿è¡Œ: pip install mlx-lm")
        except Exception as e:
            self._mlx_available = False
            logger.error(f"MLX-LM å¯¼å…¥å¤±è´¥ (å…¶ä»–é”™è¯¯): {type(e).__name__}: {e}")
            logger.error("è¯·æ£€æŸ¥ MLX-LM æ˜¯å¦æ­£ç¡®å®‰è£…: pip install mlx-lm")
    
    def load_model(self) -> bool:
        """
        åŠ è½½æ¨¡å‹åˆ°å†…å­˜ï¼ˆMLX æ–¹å¼ï¼‰
        
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        # å†æ¬¡å°è¯•å¯¼å…¥ï¼ˆä»¥é˜²è¿è¡Œæ—¶ç¯å¢ƒå˜åŒ–ï¼‰
        try:
            from mlx_lm import load, generate
        except ImportError as e:
            logger.error(f"MLX-LM å¯¼å…¥å¤±è´¥: {e}")
            logger.error("è¯·ç¡®ä¿å·²å®‰è£… MLX-LM: pip install mlx-lm")
            logger.error("å¦‚æœå·²å®‰è£…ï¼Œè¯·æ£€æŸ¥ Python ç¯å¢ƒæ˜¯å¦æ­£ç¡®")
            return False
        except Exception as e:
            logger.error(f"MLX-LM å¯¼å…¥æ—¶å‘ç”Ÿé”™è¯¯: {type(e).__name__}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
        
        if not self._mlx_available:
            logger.warning("åˆå§‹åŒ–æ—¶ MLX-LM ä¸å¯ç”¨ï¼Œä½†å½“å‰å¯¼å…¥æˆåŠŸï¼Œç»§ç»­åŠ è½½...")
        
        try:
            logger.info(f"ğŸ”„ åŠ è½½æ¨¡å‹: {self.model_path}")
            
            # æ£€æŸ¥é€‚é…å™¨è·¯å¾„ï¼ˆå¦‚æœæŒ‡å®šäº†ï¼‰
            if self.adapter_path and not self.adapter_path.exists():
                logger.error(f"é€‚é…å™¨æ–‡ä»¶ä¸å­˜åœ¨: {self.adapter_path}")
                return False
            
            # åŠ è½½æ¨¡å‹å’Œé€‚é…å™¨
            if self.adapter_path:
                logger.info(f"   ä½¿ç”¨é€‚é…å™¨: {self.adapter_path}")
                self.model, self.tokenizer = load(
                    self.model_path, 
                    adapter_path=str(self.adapter_path)
                )
            else:
                logger.info("   âš ï¸  æœªä½¿ç”¨é€‚é…å™¨ï¼ˆåŸºç¡€æ¨¡å‹ï¼‰")
                self.model, self.tokenizer = load(self.model_path)
            
            # ä¿å­˜ generate å‡½æ•°å¼•ç”¨
            self.generate_fn = generate
            
            logger.info(f"âœ… æ¨¡å‹ '{self.model_name}' åŠ è½½æˆåŠŸ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def unload_model(self):
        """å¸è½½æ¨¡å‹é‡Šæ”¾å†…å­˜"""
        if self.model:
            del self.model
            self.model = None
        if self.tokenizer:
            del self.tokenizer
            self.tokenizer = None
        if self.generate_fn:
            self.generate_fn = None
        
        logger.info(f"æ¨¡å‹ '{self.model_name}' å·²å¸è½½")
    
    def is_loaded(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½"""
        return self.model is not None and self.tokenizer is not None
    
    def generate_stream(
        self,
        prompt: str,
        max_new_tokens: int = 512,
        temperature: float = 0.7,
        top_p: float = 0.9,
        **kwargs
    ) -> Generator[str, None, None]:
        """
        æµå¼ç”Ÿæˆæ–‡æœ¬ï¼ˆMLX æ–¹å¼ï¼‰
        
        æ³¨æ„ï¼šMLX-LM çš„ generate å‡½æ•°ä¸æ”¯æŒ max_tokensã€temperatureã€top_p ç­‰å‚æ•°
        è¿™äº›å‚æ•°ä¼šè¢«å¿½ç•¥ï¼Œä½¿ç”¨æ¨¡å‹çš„é»˜è®¤è®¾ç½®
        
        Args:
            prompt: è¾“å…¥æç¤ºè¯
            max_new_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼ˆMLX ä¸æ”¯æŒï¼Œå‚æ•°ä¿ç•™ä»¥å…¼å®¹ APIï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆMLX ä¸æ”¯æŒï¼Œå‚æ•°ä¿ç•™ä»¥å…¼å®¹ APIï¼‰
            top_p: nucleus samplingå‚æ•°ï¼ˆMLX ä¸æ”¯æŒï¼Œå‚æ•°ä¿ç•™ä»¥å…¼å®¹ APIï¼‰
            
        Yields:
            ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
        """
        if not self.is_loaded():
            yield "[ERROR] æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æ¨¡å‹"
            return
        
        try:
            # MLX-LM çš„ generate å‡½æ•°åªæ”¯æŒ prompt å’Œ verbose å‚æ•°
            # å‚è€ƒ use_model.py çš„å®ç°ï¼Œä¸ä¼ é€’ max_tokensã€temperature ç­‰å‚æ•°
            response = self.generate_fn(
                self.model,
                self.tokenizer,
                prompt=prompt,
                verbose=False
            )
            
            # å°†å®Œæ•´å“åº”åˆ†å—è¿”å›ï¼ˆæ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼‰
            # å¯ä»¥æŒ‰å­—ç¬¦æˆ–æŒ‰è¯åˆ†å—
            chunk_size = 5  # æ¯æ¬¡è¿”å› 5 ä¸ªå­—ç¬¦
            for i in range(0, len(response), chunk_size):
                chunk = response[i:i + chunk_size]
                yield chunk
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            yield f"\n\n[ERROR] {str(e)}"
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        info = {
            "name": self.model_name,
            "path": self.model_path,
            "loaded": self.is_loaded(),
            "adapter_path": str(self.adapter_path) if self.adapter_path else None,
            "using_adapter": self.adapter_path is not None and not self.no_adapter,
            "framework": "MLX"
        }
        
        # å¦‚æœä½¿ç”¨äº†é€‚é…å™¨ï¼Œå°è¯•åŠ è½½é€‚é…å™¨é…ç½®ä¿¡æ¯
        if self.adapter_path and self.adapter_path.exists():
            config = load_adapter_config(self.adapter_path)
            if config:
                adapter_info = extract_adapter_info(config)
                info["adapter_config"] = adapter_info
        
        if self.is_loaded():
            info["device"] = "Apple Silicon (MLX)"
        
        return info

