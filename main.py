"""
Model Comparison Tool - FastAPI Backend
ç”¨äºå¯¹æ¯”ä¸¤ä¸ªæœ¬åœ°æ¨¡å‹çš„æ¨ç†æ•ˆæœ
"""

from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List
import logging
import asyncio
from pathlib import Path
import json
from datetime import datetime

from model_manager import ModelManager, list_all_adapters

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ•°æ®ç›®å½•è·¯å¾„
DATA_DIR = Path(__file__).parent / "data"
DATA_DIR.mkdir(exist_ok=True)

# å†å²è®°å½•æ–‡ä»¶è·¯å¾„
MODEL_PATHS_FILE = DATA_DIR / "model_paths.json"
PROMPTS_FILE = DATA_DIR / "prompts.json"


# ==================== å†å²è®°å½•å·¥å…·å‡½æ•° ====================

def load_history(file_path: Path, max_items: int = 50) -> List[str]:
    """
    åŠ è½½å†å²è®°å½•
    
    Args:
        file_path: JSON æ–‡ä»¶è·¯å¾„
        max_items: æœ€å¤§ä¿ç•™è®°å½•æ•°
        
    Returns:
        å†å²è®°å½•åˆ—è¡¨ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    """
    if not file_path.exists():
        return []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            history = data.get('history', [])
            # å»é‡å¹¶ä¿æŒé¡ºåºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            seen = set()
            unique_history = []
            for item in history:
                if item not in seen:
                    seen.add(item)
                    unique_history.append(item)
            # é™åˆ¶æ•°é‡
            return unique_history[:max_items]
    except Exception as e:
        logger.error(f"Failed to load history from {file_path}: {e}")
        return []


def save_history(file_path: Path, new_item: str, max_items: int = 50):
    """
    ä¿å­˜å†å²è®°å½•
    
    Args:
        file_path: JSON æ–‡ä»¶è·¯å¾„
        new_item: æ–°è®°å½•é¡¹
        max_items: æœ€å¤§ä¿ç•™è®°å½•æ•°
    """
    try:
        # åŠ è½½ç°æœ‰å†å²
        history = load_history(file_path, max_items * 2)
        
        # å¦‚æœæ–°é¡¹å·²å­˜åœ¨ï¼Œå…ˆç§»é™¤ï¼ˆé¿å…é‡å¤ï¼‰
        if new_item in history:
            history.remove(new_item)
        
        # å°†æ–°é¡¹æ·»åŠ åˆ°æœ€å‰é¢
        history.insert(0, new_item)
        
        # é™åˆ¶æ•°é‡
        history = history[:max_items]
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        data = {
            'history': history,
            'updated_at': datetime.now().isoformat()
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Saved history item to {file_path}")
    except Exception as e:
        logger.error(f"Failed to save history to {file_path}: {e}")

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="Model Comparison Tool",
    description="Compare two fine-tuned models side by side",
    version="1.0.0"
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€æ¨¡å‹ç®¡ç†å™¨
model_managers: Dict[str, ModelManager] = {
    "model_a": None,
    "model_b": None
}


# ==================== Pydantic Models ====================

class ModelConfig(BaseModel):
    model_path: str
    model_name: Optional[str] = None
    adapter_path: Optional[str] = None  # é€‚é…å™¨æ–‡ä»¶è·¯å¾„
    no_adapter: bool = False  # æ˜¯å¦ä¸ä½¿ç”¨é€‚é…å™¨ï¼ˆä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼‰
    saves_dir: Optional[str] = None  # é€‚é…å™¨ä¿å­˜ç›®å½•ï¼ˆç”¨äºè‡ªåŠ¨æŸ¥æ‰¾ï¼Œé»˜è®¤: mlx/savesï¼‰


class GenerateRequest(BaseModel):
    prompt: str
    model_id: str  # "model_a" or "model_b"
    max_new_tokens: int = 4096
    temperature: float = 0.7
    top_p: float = 0.9


# ==================== API Endpoints ====================

@app.get("/")
async def read_root():
    """ä¸»é¡µ"""
    return FileResponse("static/index.html")


@app.post("/api/models/{model_id}/load")
async def load_model(model_id: str, config: ModelConfig):
    """
    åŠ è½½æ¨¡å‹åˆ°å†…å­˜
    
    Args:
        model_id: "model_a" æˆ– "model_b"
        config: æ¨¡å‹é…ç½®ï¼ˆè·¯å¾„å’Œåç§°ï¼‰
    """
    if model_id not in ["model_a", "model_b"]:
        raise HTTPException(status_code=400, detail="Invalid model_id. Use 'model_a' or 'model_b'")
    
    # å¸è½½æ—§æ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if model_managers[model_id] is not None:
        logger.info(f"Unloading existing {model_id}...")
        model_managers[model_id].unload_model()
    
    # åˆ›å»ºæ–°æ¨¡å‹ç®¡ç†å™¨
    model_name = config.model_name or f"Model {model_id.upper()}"
    saves_dir = config.saves_dir or "mlx/saves"
    manager = ModelManager(
        model_path=config.model_path,
        model_name=model_name,
        adapter_path=config.adapter_path,
        no_adapter=config.no_adapter,
        saves_dir=saves_dir
    )
    
    # å¼‚æ­¥åŠ è½½æ¨¡å‹ï¼ˆåœ¨åå°çº¿ç¨‹æ‰§è¡Œä»¥é¿å…é˜»å¡ï¼‰
    logger.info(f"Loading {model_id} from {config.model_path}...")
    
    # åœ¨ executor ä¸­è¿è¡Œé˜»å¡çš„åŠ è½½æ“ä½œ
    loop = asyncio.get_event_loop()
    success = await loop.run_in_executor(None, manager.load_model)
    
    if success:
        model_managers[model_id] = manager
        return {
            "success": True,
            "message": f"Model '{model_name}' loaded successfully",
            "model_info": manager.get_model_info()
        }
    else:
        return {
            "success": False,
            "message": f"Failed to load model from {config.model_path}",
            "error": "Check server logs for details"
        }


@app.post("/api/models/{model_id}/unload")
async def unload_model(model_id: str):
    """å¸è½½æ¨¡å‹é‡Šæ”¾å†…å­˜"""
    if model_id not in ["model_a", "model_b"]:
        raise HTTPException(status_code=400, detail="Invalid model_id")
    
    if model_managers[model_id] is None:
        return {"success": False, "message": "Model not loaded"}
    
    model_managers[model_id].unload_model()
    model_managers[model_id] = None
    
    return {"success": True, "message": f"{model_id} unloaded"}


@app.get("/api/models/{model_id}/status")
async def get_model_status(model_id: str):
    """è·å–æ¨¡å‹çŠ¶æ€"""
    if model_id not in ["model_a", "model_b"]:
        raise HTTPException(status_code=400, detail="Invalid model_id")
    
    manager = model_managers[model_id]
    
    if manager is None:
        return {
            "loaded": False,
            "model_id": model_id
        }
    
    return {
        "loaded": manager.is_loaded(),
        "model_id": model_id,
        "model_info": manager.get_model_info()
    }


@app.get("/api/status")
async def get_all_status():
    """è·å–æ‰€æœ‰æ¨¡å‹çŠ¶æ€"""
    return {
        "model_a": {
            "loaded": model_managers["model_a"] is not None and model_managers["model_a"].is_loaded(),
            "info": model_managers["model_a"].get_model_info() if model_managers["model_a"] else None
        },
        "model_b": {
            "loaded": model_managers["model_b"] is not None and model_managers["model_b"].is_loaded(),
            "info": model_managers["model_b"].get_model_info() if model_managers["model_b"] else None
        }
    }


@app.get("/api/adapters")
async def get_adapters(saves_dir: Optional[str] = None):
    """
    è·å–æ‰€æœ‰å¯ç”¨çš„é€‚é…å™¨åˆ—è¡¨ï¼ŒæŒ‰æ¨¡å‹ç±»å‹åˆ†ç±»
    
    Args:
        saves_dir: é€‚é…å™¨ä¿å­˜ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤: mlx/savesï¼‰
    
    Returns:
        é€‚é…å™¨å­—å…¸ï¼ŒæŒ‰æ¨¡å‹ç±»å‹åˆ†ç±»ï¼Œæ¯ä¸ªç±»å‹ä¸‹çš„é€‚é…å™¨æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    """
    saves_dir = saves_dir or "mlx/saves"
    adapters_by_type = list_all_adapters(saves_dir)
    
    # è®¡ç®—æ€»æ•°
    total_count = sum(len(adapters) for adapters in adapters_by_type.values())
    
    return {
        "adapters_by_type": adapters_by_type,
        "model_types": list(adapters_by_type.keys()),
        "total_count": total_count
    }


@app.get("/api/history/model-paths")
async def get_model_paths_history():
    """
    è·å–æ¨¡å‹è·¯å¾„å†å²è®°å½•
    
    Returns:
        å†å²è®°å½•åˆ—è¡¨ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    """
    history = load_history(MODEL_PATHS_FILE)
    return {
        "history": history,
        "count": len(history)
    }


@app.post("/api/history/model-paths")
async def save_model_path(request: Dict[str, str]):
    """
    ä¿å­˜æ¨¡å‹è·¯å¾„åˆ°å†å²è®°å½•
    
    Args:
        request: åŒ…å« model_path çš„å­—å…¸
    """
    model_path = request.get("model_path", "").strip()
    if model_path:
        save_history(MODEL_PATHS_FILE, model_path)
        return {"success": True, "message": "Model path saved"}
    else:
        raise HTTPException(status_code=400, detail="model_path is required")


@app.get("/api/history/prompts")
async def get_prompts_history():
    """
    è·å–æç¤ºè¯å†å²è®°å½•
    
    Returns:
        å†å²è®°å½•åˆ—è¡¨ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    """
    history = load_history(PROMPTS_FILE)
    return {
        "history": history,
        "count": len(history)
    }


@app.post("/api/history/prompts")
async def save_prompt(request: Dict[str, str]):
    """
    ä¿å­˜æç¤ºè¯åˆ°å†å²è®°å½•
    
    Args:
        request: åŒ…å« prompt çš„å­—å…¸
    """
    prompt = request.get("prompt", "").strip()
    if prompt:
        save_history(PROMPTS_FILE, prompt)
        return {"success": True, "message": "Prompt saved"}
    else:
        raise HTTPException(status_code=400, detail="prompt is required")


@app.post("/api/generate/stream")
async def generate_stream(request: GenerateRequest):
    """
    æµå¼ç”Ÿæˆæ–‡æœ¬
    
    ä½¿ç”¨ Server-Sent Events (SSE) è¿”å›æµå¼å“åº”
    """
    if request.model_id not in ["model_a", "model_b"]:
        raise HTTPException(status_code=400, detail="Invalid model_id")
    
    manager = model_managers[request.model_id]
    
    if manager is None or not manager.is_loaded():
        raise HTTPException(
            status_code=400,
            detail=f"Model {request.model_id} is not loaded"
        )
    
    async def event_generator():
        """SSE äº‹ä»¶ç”Ÿæˆå™¨"""
        try:
            # åœ¨ executor ä¸­è¿è¡Œç”Ÿæˆå™¨
            loop = asyncio.get_event_loop()
            
            for text_chunk in manager.generate_stream(
                prompt=request.prompt,
                max_new_tokens=request.max_new_tokens,
                temperature=request.temperature,
                top_p=request.top_p
            ):
                # å‘é€ SSE æ ¼å¼æ•°æ®
                yield f"data: {text_chunk}\n\n"
                await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ
            
            # å‘é€ç»“æŸæ ‡è®°
            yield "data: [DONE]\n\n"
            
        except Exception as e:
            logger.error(f"Generation error: {e}")
            yield f"data: [ERROR] {str(e)}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


# æŒ‚è½½é™æ€æ–‡ä»¶
static_path = Path(__file__).parent / "static"
static_path.mkdir(exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")


# ==================== å¯åŠ¨äº‹ä»¶ ====================

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨"""
    logger.info("=" * 60)
    logger.info("ğŸš€ Model Comparison Tool Starting...")
    logger.info("=" * 60)
    logger.info("ğŸ“Š Dashboard: http://localhost:8100")
    logger.info("ğŸ“š API Docs: http://localhost:8100/docs")
    logger.info("=" * 60)


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­"""
    logger.info("Shutting down... Unloading models...")
    for model_id in ["model_a", "model_b"]:
        if model_managers[model_id] is not None:
            model_managers[model_id].unload_model()


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8100,
        log_level="info"
    )

