# Model Comparison Tool

Fine-tuned Model Side-by-Side Comparison Tool - æ¨¡å‹å¯¹æ¯”å·¥å…·

## åŠŸèƒ½ç‰¹æ€§

- âœ… æ”¯æŒåŠ è½½ä¸¤ä¸ªæœ¬åœ° MLX æ ¼å¼çš„æ¨¡å‹ï¼ˆApple Silicon ä¼˜åŒ–ï¼‰
- âœ… æ”¯æŒ LoRA é€‚é…å™¨åŠ è½½å’Œå¯¹æ¯”
- âœ… è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„é€‚é…å™¨æ–‡ä»¶
- âœ… æ”¯æŒåŸºç¡€æ¨¡å‹å’Œ Fine-tuned æ¨¡å‹å¯¹æ¯”
- âœ… æµå¼è¾“å‡ºï¼Œå®æ—¶å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„å“åº”
- âœ… åŒåˆ—å¹¶æ’æ˜¾ç¤ºï¼Œæ–¹ä¾¿è§‚å¯Ÿå·®å¼‚
- âœ… æ”¯æŒè‡ªå®šä¹‰ç”Ÿæˆå‚æ•°ï¼ˆTemperature, Top-P, Max Tokensï¼‰
- âœ… å“åº”æ—¶é—´ç»Ÿè®¡
- âœ… ç°ä»£åŒ–çš„ Web ç•Œé¢

## ç³»ç»Ÿè¦æ±‚

- Python 3.11+
- uv (Python åŒ…ç®¡ç†å™¨)
- **Apple Silicon (M1/M2/M3)** - MLX æ¡†æ¶éœ€è¦ Apple Silicon Mac
- mlx-lm (MLX è¯­è¨€æ¨¡å‹åº“)

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

ä½¿ç”¨ uv ç®¡ç†ä¾èµ–ï¼ˆæ¨èï¼‰ï¼š

```bash
cd fine-tune

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate  # macOS/Linux
# æˆ–
.venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
uv pip install -e .

# å®‰è£… MLX-LMï¼ˆå¦‚æœè¿˜æ²¡æœ‰å®‰è£…ï¼‰
uv pip install mlx-lm
```

### 2. å¯åŠ¨æœåŠ¡

```bash
# ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
python main.py
```

æˆ–ä½¿ç”¨ uvicornï¼š

```bash
uvicorn main:app --host 0.0.0.0 --port 8100 --reload
```

### 3. è®¿é—®ç•Œé¢

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼šhttp://localhost:8100

## ä½¿ç”¨è¯´æ˜

### æ­¥éª¤ 1: åŠ è½½æ¨¡å‹

#### æ–¹å¼ 1: ä½¿ç”¨ API åŠ è½½ï¼ˆæ¨èï¼‰

é€šè¿‡ API åŠ è½½æ¨¡å‹ï¼Œæ”¯æŒä»¥ä¸‹é…ç½®ï¼š

**åŠ è½½åŸºç¡€æ¨¡å‹ï¼ˆä¸ä½¿ç”¨é€‚é…å™¨ï¼‰**ï¼š
```json
POST /api/models/model_a/load
{
  "model_path": "/Users/newmind/.lmstudio/models/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
  "model_name": "Qwen3-Coder-30B (Base)",
  "no_adapter": true
}
```

**åŠ è½½å¸¦é€‚é…å™¨çš„æ¨¡å‹ï¼ˆè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ï¼‰**ï¼š
```json
POST /api/models/model_b/load
{
  "model_path": "/Users/newmind/.lmstudio/models/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
  "model_name": "Qwen3-Coder-30B (Fine-tuned)",
  "adapter_path": null,  // null è¡¨ç¤ºè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„é€‚é…å™¨
  "saves_dir": "mlx/saves/qwen-lora"
}
```

**åŠ è½½æŒ‡å®šé€‚é…å™¨çš„æ¨¡å‹**ï¼š
```json
POST /api/models/model_b/load
{
  "model_path": "/Users/newmind/.lmstudio/models/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
  "model_name": "Qwen3-Coder-30B (Fine-tuned)",
  "adapter_path": "mlx/saves/qwen-lora/train_2025-11-15-00-36-05/adapters.npz"
}
```

#### æ–¹å¼ 2: é€šè¿‡ Web ç•Œé¢åŠ è½½

1. åœ¨ **Model A** åŒºåŸŸå¡«å†™ï¼š
   - **Model Name**: åŸå§‹æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
   - **Model Path**: æ¨¡å‹çš„æœ¬åœ°è·¯å¾„æˆ– HuggingFace æ¨¡å‹ ID
   - **No Adapter**: å‹¾é€‰æ­¤é€‰é¡¹ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆä¸åŠ è½½é€‚é…å™¨ï¼‰
   - ç‚¹å‡» **Load Model** åŠ è½½æ¨¡å‹

2. åœ¨ **Model B** åŒºåŸŸå¡«å†™ï¼š
   - **Model Name**: Fine-tuned æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
   - **Model Path**: ç›¸åŒçš„æ¨¡å‹è·¯å¾„
   - **Adapter Path**: é€‚é…å™¨æ–‡ä»¶è·¯å¾„ï¼ˆç•™ç©ºåˆ™è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ï¼‰
   - ç‚¹å‡» **Load Model** åŠ è½½æ¨¡å‹

> **æç¤º**ï¼š
> - æ¨¡å‹è·¯å¾„å¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„æˆ– HuggingFace æ¨¡å‹ IDï¼ˆå¦‚ `mlx-community/Qwen2.5-3B-Instruct-4bit`ï¼‰
> - é€‚é…å™¨è·¯å¾„ç¤ºä¾‹ï¼š`mlx/saves/*/train_2025-11-15-00-36-05/adapters.npz`
> - å¦‚æœä¸æŒ‡å®šé€‚é…å™¨è·¯å¾„ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æŸ¥æ‰¾ `mlx/saves/*` ç›®å½•ä¸‹æœ€æ–°çš„é€‚é…å™¨

### æ­¥éª¤ 2: è¾“å…¥é—®é¢˜

åœ¨ **Input Prompt** åŒºåŸŸè¾“å…¥ä½ æƒ³é—®çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼š

```
è¯·è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ ä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚
```

### æ­¥éª¤ 3: è°ƒæ•´å‚æ•°ï¼ˆå¯é€‰ï¼‰

- **Max Tokens**: ç”Ÿæˆçš„æœ€å¤§ token æ•°é‡ï¼ˆé»˜è®¤ 512ï¼‰
- **Top P**: Nucleus sampling å‚æ•°ï¼ˆé»˜è®¤ 0.9ï¼‰

### æ­¥éª¤ 4: ç”Ÿæˆå¯¹æ¯”

ç‚¹å‡» **ğŸš€ Generate Comparison** æŒ‰é’®ï¼Œä¸¤ä¸ªæ¨¡å‹å°†åŒæ—¶å¼€å§‹ç”Ÿæˆå“åº”ã€‚

ä½ å¯ä»¥å®æ—¶çœ‹åˆ°ï¼š
- å·¦ä¾§ï¼šModel A çš„å“åº”
- å³ä¾§ï¼šModel B çš„å“åº”
- æ¯ä¸ªæ¨¡å‹çš„å“åº”æ—¶é—´

## æ¨¡å‹å’Œé€‚é…å™¨

### æ”¯æŒçš„æ¨¡å‹æ ¼å¼

- **MLX æ ¼å¼æ¨¡å‹**ï¼šæ”¯æŒæœ¬åœ° MLX æ¨¡å‹è·¯å¾„æˆ– HuggingFace æ¨¡å‹ ID
- **LoRA é€‚é…å™¨**ï¼šæ”¯æŒ MLX-LM è®­ç»ƒçš„ LoRA é€‚é…å™¨ï¼ˆ`.npz` æ–‡ä»¶ï¼‰

### æ¨¡å‹è·¯å¾„ç¤ºä¾‹

1. **æœ¬åœ° MLX æ¨¡å‹è·¯å¾„**ï¼š
   ```
   /Users/newmind/.lmstudio/models/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit
   ```

2. **HuggingFace æ¨¡å‹ ID**ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰ï¼š
   ```
   mlx-community/Qwen2.5-3B-Instruct-4bit
   ```

### é€‚é…å™¨è·¯å¾„

é€‚é…å™¨æ–‡ä»¶é€šå¸¸ä¿å­˜åœ¨ `mlx/saves/qwen-lora/train_YYYY-MM-DD-HH-MM-SS/adapters.npz`

**è‡ªåŠ¨æŸ¥æ‰¾é€‚é…å™¨**ï¼š
- å¦‚æœä¸æŒ‡å®š `adapter_path`ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åœ¨ `mlx/saves/qwen-lora` ç›®å½•ä¸‹æŸ¥æ‰¾æœ€æ–°çš„é€‚é…å™¨
- æŸ¥æ‰¾é€»è¾‘ï¼šæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„ `train_*/adapters.npz` æ–‡ä»¶

**æ‰‹åŠ¨æŒ‡å®šé€‚é…å™¨**ï¼š
- æä¾›å®Œæ•´çš„é€‚é…å™¨æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ï¼š
  ```
  mlx/saves/qwen-lora/train_2025-11-15-00-36-05/adapters.npz
  ```

### ä½¿ç”¨åœºæ™¯

1. **å¯¹æ¯”åŸºç¡€æ¨¡å‹ vs Fine-tuned æ¨¡å‹**ï¼š
   - Model A: åŸºç¡€æ¨¡å‹ï¼ˆ`no_adapter: true`ï¼‰
   - Model B: å¸¦é€‚é…å™¨çš„æ¨¡å‹ï¼ˆæŒ‡å®š `adapter_path`ï¼‰

2. **å¯¹æ¯”ä¸åŒç‰ˆæœ¬çš„ Fine-tuned æ¨¡å‹**ï¼š
   - Model A: ä½¿ç”¨é€‚é…å™¨ A
   - Model B: ä½¿ç”¨é€‚é…å™¨ B

## API æ–‡æ¡£

å¯åŠ¨æœåŠ¡åï¼Œè®¿é—® http://localhost:8100/docs æŸ¥çœ‹å®Œæ•´çš„ API æ–‡æ¡£ï¼ˆSwagger UIï¼‰ã€‚

### ä¸»è¦ API ç«¯ç‚¹

- `POST /api/models/{model_id}/load` - åŠ è½½æ¨¡å‹
  - è¯·æ±‚ä½“ï¼š`ModelConfig`ï¼ˆåŒ…å« `model_path`, `adapter_path`, `no_adapter` ç­‰ï¼‰
- `POST /api/models/{model_id}/unload` - å¸è½½æ¨¡å‹
- `GET /api/models/{model_id}/status` - è·å–æ¨¡å‹çŠ¶æ€
- `POST /api/generate/stream` - æµå¼ç”Ÿæˆæ–‡æœ¬
- `GET /api/status` - è·å–æ‰€æœ‰æ¨¡å‹çŠ¶æ€

### API ä½¿ç”¨ç¤ºä¾‹

**Python ç¤ºä¾‹**ï¼š
```python
import requests

# åŠ è½½åŸºç¡€æ¨¡å‹
response = requests.post("http://localhost:8100/api/models/model_a/load", json={
    "model_path": "/Users/newmind/.lmstudio/models/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
    "no_adapter": True
})

# åŠ è½½å¸¦é€‚é…å™¨çš„æ¨¡å‹
response = requests.post("http://localhost:8100/api/models/model_b/load", json={
    "model_path": "/Users/newmind/.lmstudio/models/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
    "adapter_path": "mlx/saves/qwen-lora/train_2025-11-15-00-36-05/adapters.npz"
})

# ç”Ÿæˆæ–‡æœ¬
response = requests.post("http://localhost:8100/api/generate/stream", json={
    "prompt": "ä»€ä¹ˆæ˜¯ Elasticsearchï¼Ÿ",
    "model_id": "model_a",
    "max_new_tokens": 500,
    "temperature": 0.7
})
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### GPU åŠ é€Ÿ

å¦‚æœä½ æœ‰ NVIDIA GPU å’Œ CUDAï¼š

```bash
# å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### å†…å­˜ä¼˜åŒ–

å¯¹äºå¤§æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨é‡åŒ–ï¼š

```bash
# å®‰è£… bitsandbytes
uv pip install bitsandbytes

# ä¿®æ”¹ model_manager.pyï¼Œæ·»åŠ  8-bit é‡åŒ–
load_in_8bit=True
```

### CPU ä¼˜åŒ–

å¦‚æœåªä½¿ç”¨ CPUï¼Œå»ºè®®ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆ7B ä»¥ä¸‹ï¼‰æˆ–é‡åŒ–ç‰ˆæœ¬ã€‚

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æ¨¡å‹åŠ è½½å¤±è´¥

**é”™è¯¯**: `Model path does not exist` æˆ– `MLX-LM æœªå®‰è£…`

**è§£å†³**:
- ç¡®è®¤å·²å®‰è£… MLX-LM: `pip install mlx-lm`
- ç¡®è®¤æ¨¡å‹è·¯å¾„æ­£ç¡®ï¼ˆæœ¬åœ°è·¯å¾„æˆ– HuggingFace æ¨¡å‹ IDï¼‰
- ç¡®è®¤åœ¨ Apple Silicon Mac ä¸Šè¿è¡Œï¼ˆMLX éœ€è¦ Apple Siliconï¼‰
- æ£€æŸ¥æ¨¡å‹ç›®å½•æ˜¯å¦åŒ…å«å¿…è¦çš„æ–‡ä»¶ï¼ˆ`config.json` ç­‰ï¼‰

### é—®é¢˜ 1.1: é€‚é…å™¨æœªæ‰¾åˆ°

**é”™è¯¯**: `é€‚é…å™¨æ–‡ä»¶ä¸å­˜åœ¨` æˆ– `æœªæ‰¾åˆ°ä»»ä½•é€‚é…å™¨æ–‡ä»¶`

**è§£å†³**:
- ç¡®è®¤é€‚é…å™¨æ–‡ä»¶è·¯å¾„æ­£ç¡®
- æ£€æŸ¥ `mlx/saves/qwen-lora` ç›®å½•æ˜¯å¦å­˜åœ¨
- ç¡®è®¤é€‚é…å™¨æ–‡ä»¶æ ¼å¼ä¸º `.npz`
- å¦‚æœä¸æŒ‡å®šè·¯å¾„ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„é€‚é…å™¨

### é—®é¢˜ 2: å†…å­˜ä¸è¶³

**é”™è¯¯**: Python å†…å­˜é”™è¯¯æˆ–ç³»ç»Ÿå†…å­˜ä¸è¶³

**è§£å†³**:
- ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆå¦‚ 3B æˆ– 7B æ¨¡å‹ï¼‰
- ä½¿ç”¨ 4-bit é‡åŒ–æ¨¡å‹ï¼ˆæ¨èï¼‰
- ä¸€æ¬¡åªåŠ è½½ä¸€ä¸ªæ¨¡å‹
- å‡å°‘ `max_new_tokens` å‚æ•°
- å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„åº”ç”¨

### é—®é¢˜ 3: ç”Ÿæˆé€Ÿåº¦æ…¢

**è§£å†³**:
- ç¡®ä¿åœ¨ Apple Silicon Mac ä¸Šè¿è¡Œï¼ˆMLX éœ€è¦ Apple Siliconï¼‰
- ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆ3B æˆ– 7Bï¼‰
- ä½¿ç”¨ 4-bit é‡åŒ–æ¨¡å‹
- å‡å°‘ `max_new_tokens`
- æ£€æŸ¥å…¶ä»–ç¨‹åºæ˜¯å¦å ç”¨èµ„æº
- ç¡®ä¿ä½¿ç”¨ MLX è€Œé PyTorchï¼ˆMLX åœ¨ Apple Silicon ä¸Šæ›´å¿«ï¼‰

## é¡¹ç›®ç»“æ„

```
fine-tune/
â”œâ”€â”€ pyproject.toml           # uv ä¾èµ–é…ç½®
â”œâ”€â”€ main.py                  # FastAPI åç«¯ä¸»åº”ç”¨
â”œâ”€â”€ model_manager.py         # æ¨¡å‹åŠ è½½å’Œæ¨ç†ç®¡ç†
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html          # Web å‰ç«¯ç•Œé¢
â”œâ”€â”€ README.md               # æœ¬æ–‡æ¡£
â””â”€â”€ .venv/                  # è™šæ‹Ÿç¯å¢ƒï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
```

## æŠ€æœ¯æ ˆ

- **Backend**: FastAPI + Uvicorn
- **Model Loading**: MLX-LM (Apple Silicon ä¼˜åŒ–)
- **Framework**: MLX (Apple çš„æœºå™¨å­¦ä¹ æ¡†æ¶)
- **Streaming**: Server-Sent Events (SSE)
- **Frontend**: Vanilla HTML/CSS/JavaScript
- **Package Manager**: uv

## å¼€å‘è¯´æ˜

### ä¿®æ”¹ä»£ç åé‡å¯æœåŠ¡

å¦‚æœä½¿ç”¨ `--reload` æ¨¡å¼ï¼Œä¿®æ”¹ Python æ–‡ä»¶åä¼šè‡ªåŠ¨é‡å¯ï¼š

```bash
uvicorn main:app --host 0.0.0.0 --port 8100 --reload
```

### æŸ¥çœ‹æ—¥å¿—

æœåŠ¡æ—¥å¿—ä¼šè¾“å‡ºåˆ°æ§åˆ¶å°ï¼ŒåŒ…æ‹¬ï¼š
- æ¨¡å‹åŠ è½½çŠ¶æ€
- è¯·æ±‚å¤„ç†ä¿¡æ¯
- é”™è¯¯ä¿¡æ¯

### è‡ªå®šä¹‰ç«¯å£

ä¿®æ”¹ `main.py` æœ€åä¸€è¡Œï¼š

```python
uvicorn.run(app, host="0.0.0.0", port=8100)  # æ”¹ä¸ºä½ æƒ³è¦çš„ç«¯å£
```

## è®¸å¯è¯

MIT License

## è”ç³»æ–¹å¼

é¡¹ç›®åœ°å€ï¼š/Users/xuhao/work/es/newsoft/fine-tune

---

**Enjoy comparing your models! ğŸš€**

